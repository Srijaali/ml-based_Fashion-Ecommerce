{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd52e5e",
   "metadata": {},
   "source": [
    "This notebook contains:\n",
    "\n",
    "- Basic NLP features (length, polarity, subjectivity)\n",
    "- TF-IDF + BoW\n",
    "- Sentence-BERT embeddings\n",
    "- Aspect-Based Sentiment Analysis\n",
    "- Topic modeling (LDA, NMF, BERTopic)\n",
    "- Aggregation to product-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69386870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import scipy.sparse\n",
    "\n",
    "\n",
    "# NLP libs\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "\n",
    "\n",
    "# Topic modeling / LDA\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30df98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 300000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Use the current working directory as the base\n",
    "project_root = Path.cwd().parent.parent  # adjust if needed to point to ML_DB_PROJECT\n",
    "\n",
    "# Output directory\n",
    "out_dir = project_root / \"data/ml/reviews/reviews_preprocessed\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DF_PATH = out_dir / \"reviews_preprocessed.parquet\"\n",
    "df = pd.read_parquet(DF_PATH)\n",
    "\n",
    "print(\"Rows:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87d489",
   "metadata": {},
   "source": [
    "Basic feature: lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0bc2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing basic length features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing basic length features...\")\n",
    "df['n_words'] = df['text_for_training'].fillna(\"\").str.split().apply(len)\n",
    "df['n_chars'] = df['text_for_training'].fillna(\"\").str.len()\n",
    "\n",
    "#print(df['n_words'])\n",
    "#print(df['n_chars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60953a",
   "metadata": {},
   "source": [
    "Sentiment: VADER (baseline) + TextBlob subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b6cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ND.COM\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57868ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing VADER sentiment scores and TextBlob subjectivity...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing VADER sentiment scores and TextBlob subjectivity...\")\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2217199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_compound'] = df['text_for_training'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "# Normalize to 0..1\n",
    "df['vader_compound_norm'] = (df['vader_compound'] + 1.0) / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225992a4",
   "metadata": {},
   "source": [
    "TextBlob polarity & subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8923105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tb_polarity_subjectivity(text):\n",
    "    try:\n",
    "        tb = TextBlob(str(text))\n",
    "        return tb.polarity, tb.subjectivity\n",
    "    except Exception:\n",
    "        return 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "317a9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_sub = df['text_for_training'].fillna(\"\").map(tb_polarity_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16c0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tb_polarity'] = pol_sub.map(lambda x: x[0])\n",
    "df['tb_subjectivity'] = pol_sub.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48033b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved step1 features\n"
     ]
    }
   ],
   "source": [
    "df.to_parquet(out_dir / \"reviews_fe_step1.parquet\", index=False)\n",
    "print(\"Saved step1 features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837732f",
   "metadata": {},
   "source": [
    "TF-IDF (global) and Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deb59601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix (max_features=10000)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing TF-IDF matrix (max_features=10000)...\")\n",
    "TFIDF_MAX_FEAT = 10000\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=TFIDF_MAX_FEAT)\n",
    "texts = df['text_for_training'].fillna(\"\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8d43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cee1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF saved. shape: (300000, 279)\n"
     ]
    }
   ],
   "source": [
    "scipy.sparse.save_npz(os.path.join(out_dir, 'reviews_tfidf_full.npz'), tfidf_matrix)\n",
    "\n",
    "with open(os.path.join(out_dir, 'reviews_tfidf_vectorizer_full.pkl'), 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(\"TF-IDF saved. shape:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fb3b0",
   "metadata": {},
   "source": [
    "saving CountVectorizer for ngrams if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4e8de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=20000, stop_words='english')\n",
    "cv_matrix = cv.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6186447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(os.path.join(out_dir, 'reviews_cv_ngram.npz'), cv_matrix)\n",
    "with open(os.path.join(out_dir, 'reviews_cv_ngram.pkl'), 'wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef4bb1",
   "metadata": {},
   "source": [
    "Sentence-BERT embeddings (all-MiniLM-L6-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a71da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentence-transformer model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "EMB_MODEL = 'all-MiniLM-L6-v2'\n",
    "emb_path = os.path.join(out_dir, 'reviews_bert_embeddings_full.npy')\n",
    "print(\"Loading sentence-transformer model:\", EMB_MODEL)\n",
    "model = SentenceTransformer(EMB_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37e1ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode in batches\n",
    "batch_size = 512\n",
    "n = len(texts)\n",
    "embeddings = np.memmap(emb_path, dtype='float32', mode='w+', shape=(n, model.get_sentence_embedding_dimension()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d969186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding embeddings in batches... total rows: 300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 586/586 [41:36<00:00,  4.26s/it]  \n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding embeddings in batches... total rows:\", n)\n",
    "for start in tqdm(range(0, n, batch_size)):\n",
    "    end = min(n, start + batch_size)\n",
    "    batch_texts = texts[start:end]\n",
    "    batch_emb = model.encode(batch_texts, batch_size=64, show_progress_bar=False, convert_to_numpy=True)\n",
    "    embeddings[start:end] = batch_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58282913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to c:\\Users\\ND.COM\\Desktop\\ML DB Project\\data\\ml\\reviews\\reviews_preprocessed\\reviews_bert_embeddings_full.npy\n"
     ]
    }
   ],
   "source": [
    "# flush to disk\n",
    "embeddings.flush()\n",
    "print(\"Saved embeddings to\", emb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d9623",
   "metadata": {},
   "source": [
    "Aspect-Based Sentiment Analysis(simple rule-based + sentence aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "387aa36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simple ABSA extraction (rule-based + VADER sentence sentiment)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running simple ABSA extraction (rule-based + VADER sentence sentiment)...\")\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "ASPECTS = ['fit','size','quality','material','color','price','delivery','packaging','service','comfort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b6d3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspect_sentiments(text):\n",
    "    \"\"\"\n",
    "    For each pre-defined aspect, search sentences that contain the aspect token (exact or lemma)\n",
    "    and compute an average VADER sentiment for those sentences. Returns dict aspect->score\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    try:\n",
    "        sents = sent_tokenize(str(text))\n",
    "    except Exception:\n",
    "        sents = [str(text)]\n",
    "    for asp in ASPECTS:\n",
    "        asp_sents = [s for s in sents if re.search(r'\b' + re.escape(asp) + r's?\b', s, flags=re.IGNORECASE)]\n",
    "        if not asp_sents:\n",
    "            out[asp] = None\n",
    "    else:\n",
    "        scores = [sia.polarity_scores(s)['compound'] for s in asp_sents]\n",
    "        out[asp] = np.mean(scores)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf8a9258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABSA:   0%|          | 0/300000 [00:00<?, ?it/s]c:\\Users\\ND.COM\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\ND.COM\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "ABSA: 100%|██████████| 300000/300000 [00:19<00:00, 15685.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute for all reviews (may be slow) — use tqdm\n",
    "aspect_dicts = []\n",
    "for t in tqdm(texts, desc='ABSA'):\n",
    "    aspect_dicts.append(extract_aspect_sentiments(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d485ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fit': None, 'size': None, 'quality': None, 'material': None, 'color': None, 'price': None, 'delivery': None, 'packaging': None, 'service': None, 'comfort': nan}, {'fit': None, 'size': None, 'quality': None, 'material': None, 'color': None, 'price': None, 'delivery': None, 'packaging': None, 'service': None, 'comfort': nan}]\n"
     ]
    }
   ],
   "source": [
    "print(aspect_dicts[:2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e97a4",
   "metadata": {},
   "source": [
    "Topic Modeling: LDA (Gensim) on tokenized reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71ea8e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing tokens for LDA (gensim)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing tokens for LDA (gensim)...\")\n",
    "import gensim.utils as gu\n",
    "\n",
    "# simple tokenization & stopword removal\n",
    "stoplist = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aad9532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_for_lda(text):\n",
    "    tokens = [w for w in re.findall(r\"\\b[a-z]{2,}\\b\", str(text).lower()) \n",
    "              if w not in stoplist]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bcc6766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 100%|██████████| 300000/300000 [00:03<00:00, 80207.20it/s] \n"
     ]
    }
   ],
   "source": [
    "texts_tokens = [tokenize_for_lda(t) for t in tqdm(texts, desc='tokenizing')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8f51cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary & corpus\n",
    "dictionary = corpora.Dictionary(texts_tokens)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=50000)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a588cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA model with 30 topics... This may take a while.\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model\n",
    "NUM_TOPICS = 30\n",
    "print(\"Training LDA model with\", NUM_TOPICS, \"topics... This may take a while.\")\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=NUM_TOPICS, passes=5, random_state=42)\n",
    "lda_model.save(os.path.join(out_dir, 'lda_model_full'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9aa4e575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing topic distributions for each document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lda infer: 100%|██████████| 300000/300000 [01:56<00:00, 2575.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute topic distribution per document\n",
    "print(\"Computing topic distributions for each document...\")\n",
    "lda_topic_dist = np.zeros((n, NUM_TOPICS), dtype=float)\n",
    "for i, bow in enumerate(tqdm(corpus, desc='lda infer')):\n",
    "    topics = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    for tid, prob in topics:\n",
    "        lda_topic_dist[i, tid] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f17f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LDA topic distributions\n"
     ]
    }
   ],
   "source": [
    "np.save(os.path.join(out_dir, 'lda_topic_dist.npy'), lda_topic_dist)\n",
    "print(\"Saved LDA topic distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffe857",
   "metadata": {},
   "source": [
    "BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #from bertopic import BERTopic\n",
    "    print(\"Running BERTopic (this requires significant memory)...\")\n",
    "    # load embeddings from memmap\n",
    "    emb = np.load(emb_path, mmap_mode='r')\n",
    "    topic_model = BERTopic(nr_topics='auto', language='english')\n",
    "    topics, probs = topic_model.fit_transform(texts, emb)\n",
    "    topic_model.save(os.path.join(out_dir, 'bertopic_model'))\n",
    "    # save topic assignments\n",
    "    df['bertopic_topic'] = topics\n",
    "    print(\"BERTopic done\")\n",
    "except Exception as e:\n",
    "    print(\"BERTopic not run (missing package or OOM). Reason:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421ad0e",
   "metadata": {},
   "source": [
    "Review-to-Product Feature Linking (Aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56a3a9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating review-level features to product level...\n"
     ]
    }
   ],
   "source": [
    "print(\"Aggregating review-level features to product level...\")\n",
    "\n",
    "# choose features to aggregate\n",
    "agg_funcs = {\n",
    "    'vader_compound_norm': ['mean', 'std'],\n",
    "    'tb_polarity': ['mean'],\n",
    "    'n_words': ['mean'],\n",
    "    'rating': ['mean','std','count']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27e9bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect columns normalized\n",
    "aspect_norm_cols = [c for c in df.columns if c.startswith('aspect_') and c.endswith('_norm')]\n",
    "for c in aspect_norm_cols:\n",
    "    agg_funcs[c] = ['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "972fa7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'customer_id', 'article_id', 'category_id', 'rating',\n",
       "       'review_text', 'created_at', 'verified_purchase', 'helpful_votes',\n",
       "       'synthetic_sentiment_label', 'aspect_terms', 'language',\n",
       "       'review_source', 'review_age_days', 'clean_text', 'vader_score',\n",
       "       'vader_label', 'aspect_terms_list', 'tokens', 'lemmas', 'sentences',\n",
       "       'language_detected', 'translated_text', 'is_spam', 'final_text_for_ml',\n",
       "       'text_for_training', 'n_words', 'n_chars', 'vader_compound',\n",
       "       'vader_compound_norm', 'tb_polarity', 'tb_subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "613669b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic proportions (LDA)\n",
    "# we'll compute average topic probability per product\n",
    "topic_cols = [f'topic_{i}' for i in range(NUM_TOPICS)]\n",
    "lda_df = pd.DataFrame(lda_topic_dist, columns=topic_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0201ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lda topic cols into df for aggregation\n",
    "df_topics = pd.concat([df.reset_index(drop=True), lda_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f6199b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product aggregation\n",
    "prod_agg = df_topics.groupby('article_id').agg(agg_funcs)\n",
    "# flatten multiindex\n",
    "prod_agg.columns = ['_'.join(col).strip() for col in prod_agg.columns.values]\n",
    "prod_agg.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a90c3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic averages\n",
    "topic_agg = df_topics.groupby('article_id')[topic_cols].mean().reset_index()\n",
    "prod_features = prod_agg.merge(topic_agg, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36b75a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ND.COM\\AppData\\Local\\Temp\\ipykernel_8528\\3267389241.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  prod_features['pct_negative'] = df_topics.groupby('article_id').apply(lambda g: (g['rating']<=2).sum()/len(g)).values\n"
     ]
    }
   ],
   "source": [
    "# additional product features\n",
    "prod_features['pct_negative'] = df_topics.groupby('article_id').apply(lambda g: (g['rating']<=2).sum()/len(g)).values\n",
    "#prod_features['review_freshness'] = df_topics.groupby('article_id').apply(lambda g: np.exp(- (pd.to_datetime('now') - pd.to_datetime(g['created_at'])).dt.days.mean()/30)).values\n",
    "prod_features['controversy_score'] = prod_features['rating_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76ca03",
   "metadata": {},
   "source": [
    "Most common complaints: top TF-IDF terms among negative reviews for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85abb9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing top complaint keywords per product...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing top complaint keywords per product...\")\n",
    "\n",
    "neg = df_topics[df_topics['rating']<=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c87cdb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "complaints: 100%|██████████| 4459/4459 [00:22<00:00, 195.53it/s]\n"
     ]
    }
   ],
   "source": [
    "prod_complaints = {}\n",
    "for aid, group in tqdm(neg.groupby('article_id'), desc='complaints'):\n",
    "    texts_group = group['text_for_training'].tolist()\n",
    "    if len(texts_group) < 3:\n",
    "        prod_complaints[aid] = []\n",
    "        continue\n",
    "    v = TfidfVectorizer(stop_words='english', max_features=50)\n",
    "    m = v.fit_transform(texts_group)\n",
    "    scores = np.asarray(m.sum(axis=0)).ravel()\n",
    "    terms = v.get_feature_names_out()\n",
    "    top_idx = np.argsort(scores)[-10:][::-1]\n",
    "    prod_complaints[aid] = [terms[i] for i in top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87c756a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "prod_complaints_df = pd.DataFrame([{'article_id':k, 'complaints':v} for k,v in prod_complaints.items()])\n",
    "prod_features = prod_features.merge(prod_complaints_df, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5f8be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved product-level features\n"
     ]
    }
   ],
   "source": [
    "# Save product-level features\n",
    "prod_features.to_parquet(os.path.join(out_dir, 'product_review_features.parquet'), index=False)\n",
    "print(\"Saved product-level features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a51e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full review-level features\n"
     ]
    }
   ],
   "source": [
    "df_topics.to_parquet(os.path.join(out_dir, 'reviews_features_full.parquet'), index=False)\n",
    "print(\"Saved full review-level features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068a7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
